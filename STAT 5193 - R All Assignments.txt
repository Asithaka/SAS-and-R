Assignment 02

> #1a.
> 
> #-----------------------------------------------------------------------------------------------------------------------
> 
> txt.sent<-c(1,10,150,18,30,100,20,100,150,75,75,50,25,100,30,5,20,200,50,10,100,100,30,10,30,10,9,100,11,2,10,5,10,5,25)
> FB.time<-c(30,20,80,45,20,60,5,20,20,20,60,5,5,60,20,0,10,60,30,120,30,25,120,0,50,5,10,30,80,10,60,15,30,5,40)
> Snapchat<-c("Y","Y","Y","Y","Y","Y","Y","Y","Y","Y","Y","Y","N","Y","Y","N","Y","Y","Y","Y","Y","Y","Y","N","N","Y","Y","Y","N","N","N","N","N","N","N")
> 
> #1b.
> 
> #-----------------------------------------------------------------------------------------------------------------------
> 
> mode(txt.sent)
[1] "numeric"
> mode(FB.time)
[1] "numeric"
> mode(Snapchat)
[1] "character"
> 
> #1a.
> 
> #-----------------------------------------------------------------------------------------------------------------
> 
> text_sent<-c(1,10,150,18,30,100,20,100,150,75,75,50,25,100,30,5,20,200,50,10,100,100,30,10,30,10,9,100,11,2,10,5,10,5,25)
> text_received<-c(1,15,150,28,30,75,20,100,150,75,75,50,30,100,30,5,40,200,50,10,100,100,30,10,30,20,3,200,15,3,10,5,15,5,25)
> FB_time<-c(30,20,80,45,20,60,5,20,20,20,60,5,5,60,20,0,10,60,30,120,30,25,120,0,50,5,10,30,80,10,60,15,30,5,40)
> 
> #1b.
> 
> #-----------------------------------------------------------------------------------------------------------------
> 
> 
> text_sent[c(1,3)]
[1]   1 150
> text_received[c(1,3)]
[1]   1 150
> FB_time[c(1,3)]
[1] 30 80
> 
> 
> #1c.
> 
> #-----------------------------------------------------------------------------------------------------------------
> 
> mode(text_sent)
[1] "numeric"
> 
> #1d.
> 
> #-----------------------------------------------------------------------------------------------------------------
> 
> snapchat<-c("Y","Y","Y","Y","Y","Y","Y","Y","Y","Y","Y","Y","N","Y","Y","N","Y","Y","Y","Y","Y","Y","Y","N","N","Y","Y","Y","N","N","N","N","N","N","N")
> snapchat[1:2]
[1] "Y" "Y"
> 
> #1e.
> 
> #-----------------------------------------------------------------------------------------------------------------
> 
> mode(snapchat)
[1] "character"
> mean(snapchat)
[1] NA
Warning message:
In mean.default(snapchat) :
  argument is not numeric or logical: returning NA
> 
> #2a.
> 
> #-----------------------------------------------------------------------------------------------------------------
> 
> 
> SM<-cbind(text_sent,text_received,FB_time)
> rownames(SM)<-c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35)
> colnames(SM)<-c("text sent","text received","FB time")
> SM[1:4,]
  text sent text received FB time
1         1             1      30
2        10            15      20
3       150           150      80
4        18            28      45
> 
> #2b.
> 
> #-----------------------------------------------------------------------------------------------------------------
> 
> class(SM)
[1] "matrix"
> dim(SM)
[1] 35  3
> 
> #2c.
> 
> #-----------------------------------------------------------------------------------------------------------------
> 
> mean(text_sent-text_received)
[1] -3.685714
> median(text_sent-text_received)
[1] 0
> 
> 
> #2d.
> 
> #-----------------------------------------------------------------------------------------------------------------
> 
> SM2<-cbind(SM,snapchat)
> 
> #2e.
> 
> #-----------------------------------------------------------------------------------------------------------------
> 
> summary(SM)
   text sent      text received       FB time      
 Min.   :  1.00   Min.   :  1.00   Min.   :  0.00  
 1st Qu.: 10.00   1st Qu.: 12.50   1st Qu.: 10.00  
 Median : 25.00   Median : 30.00   Median : 25.00  
 Mean   : 47.89   Mean   : 51.57   Mean   : 34.29  
 3rd Qu.: 87.50   3rd Qu.: 75.00   3rd Qu.: 55.00  
 Max.   :200.00   Max.   :200.00   Max.   :120.00  
> summary(SM2)
   text sent  text received    FB time  snapchat
 10     : 6   30     : 5    20     :6   N:11    
 100    : 6   100    : 4    30     :5   Y:24    
 30     : 4   10     : 3    5      :5           
 5      : 3   15     : 3    60     :5           
 150    : 2   5      : 3    10     :3           
 20     : 2   75     : 3    0      :2           
 (Other):12   (Other):14    (Other):9           
> 
> #  mode of SM is newmeric.Therefore minimum,maximum,mean,median and quartiles can be defined. But mode of SM2 is character.Then for character mode minimum,maximum,mean,median and quartiles can not be defined.That is why we have a different output for summary.
> 
> 
> #2e.
> 
> #-----------------------------------------------------------------------------------------------------------------
> dim1<-c('no1','no2','no3','no4','no5','no6','no7','no8','no9','no10','no11','no12','no13','no14','no15','no16','no17','no18','no19','no20',
+ 'no21','no22','no23','no24','no25','no26','no27','no28','no29','no30','no31','no32','no33','no34','no35')
> 
> dim2<-c('text sent1','text received1','FB time1')
> 
> SM.Array<-array(SM,c(35,3),list(dim1,dim2))
> 
> SM.Array[c(1,35),c(1:3)]
     text sent1 text received1 FB time1
no1           1              1       30
no35         25             25       40
> 
> 
> 


Assignment 03

> "No" #Each vector does not belong to same class
[1] "No"
> 
> #1c.
> 
> #-----------------------------------------------------------------------------------------------------------------------
> 
> class(txt.sent)
[1] "numeric"
> class(FB.time)
[1] "numeric"
> class(Snapchat)
[1] "character"
> 
> "No" #Each vector does not belong to same class
[1] "No"
> 
> 
> #1d.
> 
> #-----------------------------------------------------------------------------------------------------------------------
> 
> ALK<-data.frame(txt.sent,FB.time,Snapchat)
> ALK[1:3,]
  txt.sent FB.time Snapchat
1        1      30        Y
2       10      20        Y
3      150      80        Y
> 
> 
> #1e.
> 
> #-----------------------------------------------------------------------------------------------------------------------
> 
> summary(ALK)
    txt.sent         FB.time       Snapchat
 Min.   :  1.00   Min.   :  0.00   N:11    
 1st Qu.: 10.00   1st Qu.: 10.00   Y:24    
 Median : 25.00   Median : 25.00           
 Mean   : 47.89   Mean   : 34.29           
 3rd Qu.: 87.50   3rd Qu.: 55.00           
 Max.   :200.00   Max.   :120.00           
> 
> # 24 of 35 student have snapchat accounts and 11 students do not have the snapchat acooutnt.Therefore the proportion is 24 to 11.The ratio of the student who have snapchat account is 24/35.
> 
> 
> #1f.
> 
> #-----------------------------------------------------------------------------------------------------------------------
> 
> boxplot(FB.time~Snapchat)
> 
> #2ai-ii.
> 
> #-----------------------------------------------------------------------------------------------------------------------
> 
> set.seed(1)
> x<-rpois(25,1)
> 
> x.f<-factor(x,order=T)
> 
> #2bi.
> 
> #-----------------------------------------------------------------------------------------------------------------------
> 
> 
> help(table)
> 
> #answer " combination of factor "
> 
> #2bii.
> 
> #-----------------------------------------------------------------------------------------------------------------------
> 
> table(x.f)
x.f
 0  1  2  3  4 
 8 10  4  2  1 
> plot(table(x.f))
> 
> 
> #3ai-iv.
> 
> #-----------------------------------------------------------------------------------------------------------------------
> 
> ALK<-list(my.name="Asitha Lakmal" ,D=diag(x = 1, 2, 2),summary=summary(ALK))
> 
> 
> #3b.
> 
> #-----------------------------------------------------------------------------------------------------------------------
> 
> ALK_new<-ALK[1:2]
> 
> ALK_new[[2]]
     [,1] [,2]
[1,]    1    0
[2,]    0    1
> 
> 
> 
> 
> 
> 
> 


Assignment 05

> #1.
> 
> #---------------------------------------------------------------------------------
> #1a.
>  
> #--------------------------------------------------------------------------------------------------------------------------------
> 
> setwd("C:/Users/akaruna/Desktop/R-DATA") 
> getwd()
[1] "C:/Users/akaruna/Desktop/R-DATA"
> my.data<-read.csv(file="StudentData.csv",header=T)
> attach(my.data)
> 
> new.TxtRec<-TxtRec[-28]
> new.TxtSent<-TxtSent[-28]
> new.Introvert<-Introvert[-28]
> 
> 
> plot((new.TxtRec -new.TxtSent)~new.Introvert,xlab="Introversion Level"
+ ,ylab="Texts Received-Texts Sent",ylim=c(-20,100))
> 
> #1b.
>  
> #--------------------------------------------------------------------------------------------------------------------------------
> #1a-d.
> 
> #--------------------------------------------------------------------------------------------------------------------------------
> 
> 
> setwd("C:/Users/akaruna/Desktop/R-DATA")
> 
> getwd()
[1] "C:/Users/akaruna/Desktop/R-DATA"
> 
> Student.Data<-read.csv(file="old.csv",header=T)
> 
> demo("colors")


        demo(colors)
        ---- ~~~~~~

Type  <Return>   to start : 

> ### ----------- Show (almost) all named colors ---------------------
> 
> ## 1) with traditional 'graphics' package:
> showCols1 <- function(bg = "gray", cex = 0.75, srt = 30) {
+     m <- ceiling(sqrt(n <- length(cl <- colors())))
+     length(cl) <- m*m; cm <- matrix(cl, m)
+     ##
+     require("graphics")
+     op <- par(mar=rep(0,4), ann=FALSE, bg = bg); on.exit(par(op))
+     plot(1:m,1:m, type="n", axes=FALSE)
+     text(col(cm), rev(row(cm)), cm,  col = cl, cex=cex, srt=srt)
+ }

> showCols1()
Waiting to confirm page change...

> ## 2) with 'grid' package:
> showCols2 <- function(bg = "grey", cex = 0.75, rot = 30) {
+     m <- ceiling(sqrt(n <- length(cl <- colors())))
+     length(cl) <- m*m; cm <- matrix(cl, m)
+     ##
+     require("grid")
+     grid.newpage(); vp <- viewport(w = .92, h = .92)
+     grid.rect(gp=gpar(fill=bg))
+     grid.text(cm, x = col(cm)/m, y = rev(row(cm))/m, rot = rot,
+               vp=vp, gp=gpar(cex = cex, col = cm))
+ }

> showCols2()
Loading required package: grid
Waiting to confirm page change...

> showCols2(bg = "gray33")
Waiting to confirm page change...

> ###
> 
> ##' @title Comparing Colors
> ##' @param col
> ##' @param nrow
> ##' @param ncol
> ##' @param txt.col
> ##' @return the grid layout, invisibly
> ##' @author Marius Hofert, originally
> plotCol <- function(col, nrow=1, ncol=ceiling(length(col) / nrow),
+                     txt.col="black") {
+     stopifnot(nrow >= 1, ncol >= 1)
+     if(length(col) > nrow*ncol)
+         warning("some colors will not be shown")
+     require(grid)
+     grid.newpage()
+     gl <- grid.layout(nrow, ncol)
+     pushViewport(viewport(layout=gl))
+     ic <- 1
+     for(i in 1:nrow) {
+         for(j in 1:ncol) {
+             pushViewport(viewport(layout.pos.row=i, layout.pos.col=j))
+             grid.rect(gp= gpar(fill=col[ic]))
+             grid.text(col[ic], gp=gpar(col=txt.col))
+             upViewport()
+             ic <- ic+1
+         }
+     }
+     upViewport()
+     invisible(gl)
+ }

> ## A Chocolate Bar of colors:
> plotCol(c("#CC8C3C", paste0("chocolate", 2:4),
+           paste0("darkorange", c("",1:2)), paste0("darkgoldenrod", 1:2),
+           "orange", "orange1", "sandybrown", "tan1", "tan2"),
+         nrow=2)
Waiting to confirm page change...

> ##' Find close R colors() to a given color {original by Marius Hofert)
> ##' using Euclidean norm in (HSV / RGB / ...) color space
> nearRcolor <- function(rgb, cSpace = c("hsv", "rgb255", "Luv", "Lab"),
+                        dist = switch(cSpace, "hsv" = 0.10, "rgb255" = 30,
+                        "Luv" = 15, "Lab" = 12))
+ {
+     if(is.character(rgb)) rgb <- col2rgb(rgb)
+     stopifnot(length(rgb <- as.vector(rgb)) == 3)
+     Rcol <- col2rgb(.cc <- colors())
+     uniqC <- !duplicated(t(Rcol)) # gray9 == grey9 (etc)
+     Rcol <- Rcol[, uniqC] ; .cc <- .cc[uniqC]
+     cSpace <- match.arg(cSpace)
+     convRGB2 <- function(Rgb, to)
+         t(convertColor(t(Rgb), from="sRGB", to=to, scale.in=255))
+     ## the transformation,  rgb{0..255} --> cSpace :
+     TransF <- switch(cSpace,
+                      "rgb255" = identity,
+                      "hsv" = rgb2hsv,
+                      "Luv" = function(RGB) convRGB2(RGB, "Luv"),
+                      "Lab" = function(RGB) convRGB2(RGB, "Lab"))
+     d <- sqrt(colSums((TransF(Rcol) - as.vector(TransF(rgb)))^2))
+     iS <- sort.list(d[near <- d <= dist])# sorted: closest first
+     setNames(.cc[near][iS], format(zapsmall(d[near][iS]), digits=3))
+ }

> nearRcolor(col2rgb("tan2"), "rgb")
         0.0         21.1         25.8         29.5 
      "tan2"       "tan1" "sandybrown"    "sienna1" 

> nearRcolor(col2rgb("tan2"), "hsv")
      0.0000       0.0410       0.0618       0.0638       0.0667       0.0766 
      "tan2"    "sienna2"     "coral2"    "tomato2"       "tan1"      "coral" 
      0.0778       0.0900       0.0912       0.0918 
   "sienna1" "sandybrown"     "coral1"     "tomato" 

> nearRcolor(col2rgb("tan2"), "Luv")
        0.00         7.42         7.48        12.41        13.69 
      "tan2"       "tan1" "sandybrown"    "orange3"    "orange2" 

> nearRcolor(col2rgb("tan2"), "Lab")
        0.00         5.56         8.08        11.31 
      "tan2"       "tan1" "sandybrown"       "peru" 

> nearRcolor("#334455")
         0.0867 
"darkslategray" 

> ## Now, consider choosing a color by looking in the
> ## neighborhood of one you know :
> 
> plotCol(nearRcolor("deepskyblue", "rgb", dist=50))
Waiting to confirm page change...

> plotCol(nearRcolor("deepskyblue", dist=.1))
Waiting to confirm page change...

> plotCol(nearRcolor("tomato", "rgb", dist= 50), nrow=3)
Waiting to confirm page change...

> plotCol(nearRcolor("tomato", "hsv", dist=.12), nrow=3)
Waiting to confirm page change...

> plotCol(nearRcolor("tomato", "Luv", dist= 25), nrow=3)
Waiting to confirm page change...

> plotCol(nearRcolor("tomato", "Lab", dist= 18), nrow=3)
Waiting to confirm page change...
> help(boxplot)
> 
> boxplot(Fbtime~Gender,data=Student.Data,xlab="class",ylab="time",names=c("F","M"),col=c("pink","blue"),main="Facebook Time vs. Gender")
> 
> 
> #2a-e.
> 
> #--------------------------------------------------------------------------------------------------------------------------------
> 
> getwd()
[1] "C:/Users/akaruna/Desktop/R-DATA"
> 
> new2<-read.csv(file="new.csv",header=T)
> 
> plot(new2$Fbtime,new2$Introvert,xlab="FB time",ylab="Introversion",main="FB vs. Introversion vs. Gender",col=new2$Gender, pch=as.vector(new2$Gender))
> 
> asi<-rbind(new2,list("M", "STAT2023", 65, 150, 150, 80, "N", "Y", 1))
> 
> points(80,1,pch=2,col="BLUE",type="p")
> 
> abline(lm(asi$Introvert~asi$Fbtime),col=3,lty=1)
> 
> abline(lm(new2$Introvert~new2$Fbtime),col=4,lty=2)
> 
> 


Assignment 06

> 
> 
> title(main="Texting vs. Introversion",col.main="Blue",cex.main=2,font.main=4)
> 
> #1c.
>  
> #--------------------------------------------------------------------------------------------------------------------------------
> 
> title(sub="Scale:1-10",cex.sub=0.8)
> 
> #1d.
>  
> #--------------------------------------------------------------------------------------------------------------------------------
> 
> abline(h=0,col="blue",lty=2)
> 
> #1e.
>  
> #--------------------------------------------------------------------------------------------------------------------------------
> 
> points(6,100,col="red",pch=2,type="p")
> text(6,100,labels="Outlier",pos=4)
> 
> #############################################Quetion no 2#############################################################################
> 
> #2a.
>  
> #--------------------------------------------------------------------------------------------------------------------------------
> 
> plot((new.TxtRec -new.TxtSent)~new.Introvert,xlab="Introversion Level"
+ ,ylab="Texts Received-Texts Sent",ylim=c(-25,20))
> 
> title(main="Outlier Analysis",col.main="Blue",cex.main=2,font.main=4)
> 
> title(sub="Scale:1-10",cex.sub=0.8)
> 
> abline(h=0,col="blue",lty=2)
> 
> #2b.
>  
> #--------------------------------------------------------------------------------------------------------------------------------
> 
> abline(lm((TxtRec -TxtSent)~Introvert),col="red",lty=1,lwd=2)
> 
> #2c.
>  
> #--------------------------------------------------------------------------------------------------------------------------------
> 
> abline(lm((new.TxtRec -new.TxtSent)~new.Introvert),col="black",lty=2,lwd=2)
> 
> #2d.
>  
> #--------------------------------------------------------------------------------------------------------------------------------
> 
> legend("bottomleft",title="Fits",c("With Outlier","Without Outlier"),lty=c(1,2),col=c("red","black"),inset=0.05,lwd=c(2,2))
> 
> #############################################Quetion no 3#############################################################################
> 
> #3a.
>  
> #--------------------------------------------------------------------------------------------------------------------------------
> 
> 
> plot((TxtRec -TxtSent)~Introvert,xlab="Introversion Level"
+ ,ylab="Texts Received-Texts Sent",pch=as.numeric(Gender),col=Gender)
> 
> #3b.
>  
> #--------------------------------------------------------------------------------------------------------------------------------
> 
> title(main="Texting vs. Introversion vs. Gender")
> 
> #3c.
>  
> #--------------------------------------------------------------------------------------------------------------------------------
> 
> legend("topleft",title="Gender",c("F","M"),inset=0.05,col=c("red","black"),pch=c(2,1))
> 
> 
> 
> 
> 
> 
> 


Assignment 07

> 
> 
> AL<-read.table(file="http://jdhabiger.okstate.edu/StudentData.txt",header=T)
> ALK<-data.frame(AL)
> str(AL)
'data.frame':   35 obs. of  9 variables:
 $ Gender   : Factor w/ 2 levels "F","M": 2 2 2 1 1 1 2 1 1 1 ...
 $ Class    : Factor w/ 2 levels "STAT2023","STAT5063": 1 1 1 1 1 1 1 1 1 1 ...
 $ HSClass  : int  1 15 65 123 130 140 142 200 200 220 ...
 $ TxtSent  : int  1 10 150 18 30 100 20 100 150 75 ...
 $ TxtRec   : int  1 15 150 28 30 75 20 100 150 75 ...
 $ Fbtime   : int  30 20 80 45 20 60 5 20 20 20 ...
 $ Pinterest: Factor w/ 2 levels "N","Y": 1 1 1 1 1 2 1 2 2 2 ...
 $ Snapchat : Factor w/ 2 levels "N","Y": 2 2 2 2 2 2 2 2 2 2 ...
 $ Introvert: num  8 8 1 4 4 6 5 6 3 5 ...
> 
> #2.
> 
> #---------------------------------------------------------------------------------
> 
> ALK$HSClass[ALK$HSClass==1]<-NA
> ALK$TxtSent[ALK$TxtSent==1]<-NA
> ALK$TxtRec[ALK$TxtRec ==1]<-NA
> ALK[1:3,]
  Gender    Class HSClass TxtSent TxtRec Fbtime Pinterest Snapchat Introvert
1      M STAT2023      NA      NA     NA     30         N        Y         8
2      M STAT2023      15      10     15     20         N        Y         8
3      M STAT2023      65     150    150     80         N        Y         1
> str(ALK)
'data.frame':   35 obs. of  9 variables:
 $ Gender   : Factor w/ 2 levels "F","M": 2 2 2 1 1 1 2 1 1 1 ...
 $ Class    : Factor w/ 2 levels "STAT2023","STAT5063": 1 1 1 1 1 1 1 1 1 1 ...
 $ HSClass  : int  NA 15 65 123 130 140 142 200 200 220 ...
 $ TxtSent  : int  NA 10 150 18 30 100 20 100 150 75 ...
 $ TxtRec   : int  NA 15 150 28 30 75 20 100 150 75 ...
 $ Fbtime   : int  30 20 80 45 20 60 5 20 20 20 ...
 $ Pinterest: Factor w/ 2 levels "N","Y": 1 1 1 1 1 2 1 2 2 2 ...
 $ Snapchat : Factor w/ 2 levels "N","Y": 2 2 2 2 2 2 2 2 2 2 ...
 $ Introvert: num  8 8 1 4 4 6 5 6 3 5 ...
> #The data set has 9 variables
> 
> #3.
> 
> #---------------------------------------------------------------------------------
> 
> ALK$d.text<-ALK$TxtSent-ALK$TxtRec
> ALK[c(1:3,10,4:9)][1:3,]
  Gender    Class HSClass d.text TxtSent TxtRec Fbtime Pinterest Snapchat Introvert
1      M STAT2023      NA     NA      NA     NA     30         N        Y         8
2      M STAT2023      15     -5      10     15     20         N        Y         8
3      M STAT2023      65      0     150    150     80         N        Y         1
> 
> #4.
> 
> #---------------------------------------------------------------------------------
> 
> ALK$Introvert.cat[ALK$Introvert<5]<-"L"
> ALK$Introvert.cat[ALK$Introvert>=5]<-"H"
> cleaned.SM<-ALK
> str(cleaned.SM)
'data.frame':   35 obs. of  11 variables:
 $ Gender       : Factor w/ 2 levels "F","M": 2 2 2 1 1 1 2 1 1 1 ...
 $ Class        : Factor w/ 2 levels "STAT2023","STAT5063": 1 1 1 1 1 1 1 1 1 1 ...
 $ HSClass      : int  NA 15 65 123 130 140 142 200 200 220 ...
 $ TxtSent      : int  NA 10 150 18 30 100 20 100 150 75 ...
 $ TxtRec       : int  NA 15 150 28 30 75 20 100 150 75 ...
 $ Fbtime       : int  30 20 80 45 20 60 5 20 20 20 ...
 $ Pinterest    : Factor w/ 2 levels "N","Y": 1 1 1 1 1 2 1 2 2 2 ...
 $ Snapchat     : Factor w/ 2 levels "N","Y": 2 2 2 2 2 2 2 2 2 2 ...
 $ Introvert    : num  8 8 1 4 4 6 5 6 3 5 ...
 $ d.text       : int  NA -5 0 -10 0 25 0 0 0 0 ...
 $ Introvert.cat: chr  "H" "H" "L" "L" ...
> 
> #5.
> 
> #---------------------------------------------------------------------------------
> 
> Ordered.SM<-cleaned.SM[order(cleaned.SM$Gender,cleaned.SM$Introvert),]
> Ordered.SM[1:5,]
   Gender    Class HSClass TxtSent TxtRec Fbtime Pinterest Snapchat Introvert d.text Introvert.cat
32      F STAT5063     160       5      5     15         N        N         2      0             L
9       F STAT2023     200     150    150     20         Y        Y         3      0             L
17      F STAT2023     760      20     40     10         Y        Y         3    -20             L
18      F STAT2023     776     200    200     60         Y        Y         3      0             L
20      F STAT2023     850      10     10    120         Y        Y         3      0             L
> 
> 
> #6.
> 
> #---------------------------------------------------------------------------------
> 
> set.seed(1)
> NewT<-sample(1:nrow(cleaned.SM),35,replace=T)
> mean(cleaned.SM[NewT,]$Introvert,trim=0.1)
[1] 4.965517
> 
> #10% trimmed mean of introvert for original data.
> 
> mean(ALK$Introvert,trim=0.1)
[1] 4.87931
> 
> # The mean of  introvert for sample data is  4.965517 
> # The mean of  introvert for original data is  4.87931 
> 
> 



Assignment 08

> #1a.
> 
> #-------------------------------------------------------------------------------------------------------
> 
> rm(list=ls())
> 
> setwd("C:/Users/akaruna/Desktop/R-DATA")
> 
> getwd()
[1] "C:/Users/akaruna/Desktop/R-DATA"
> 
> source("Day8Script (1).R")
> 
> roster
    Firstname   Lastname Math Science English score grade
6      Cheryl    Cushing  512      85      28  0.35     C
1        John      Davis  502      95      25  0.56     B
9        Joel    England  573      89      27  0.70     B
4       David      Jones  358      82      15 -1.16     F
8        Greg       Knox  625      95      30  1.34     A
5      Janice Markhammer  495      75      20 -0.63     D
3  Bullwinkle      Moose  412      80      18 -0.86     D
10       Mary    Rayburn  522      86      18 -0.18     C
2      Angela   Williams  600      99      22  0.92     A
7      Reuven    Ytzrhak  410      80      15 -1.05     F
> 
> ls()
 [1] "col"       "English"   "First"     "Firstname" "Last"      "Lastname" 
 [7] "Math"      "mu"        "mvn.data"  "n"         "name"      "rho"      
[13] "roster"    "Science"   "score"     "Sigma"     "Student"   "sums"     
[19] "t.data"    "x"         "y"         "z"        
> 
> #1b.
> 
> #-------------------------------------------------------------------------------------------------------
> 
> score
 [1]  0.56  0.92 -0.86 -1.16 -0.63  0.35 -1.05  1.34  0.70 -0.18
> 
> roster$score
 [1]  0.35  0.56  0.70 -1.16  1.34 -0.63 -0.86 -0.18  0.92 -1.05
> 
> # roster <- roster[order(Lastname,Firstname),]
> 
> #1c.
> 
> #-------------------------------------------------------------------------------------------------------
> 
> y<-quantile(roster$score,c(0.75,0.25))
> 
> roster$easygrade[roster$score >= y[1]]<- "A"
> roster$easygrade[roster$score < y[1] & roster$score >= y[2] ]<- "B"
> roster$easygrade[roster$score < y[2]]<- "C"
> roster
    Firstname   Lastname Math Science English score grade easygrade
6      Cheryl    Cushing  512      85      28  0.35     C         B
1        John      Davis  502      95      25  0.56     B         B
9        Joel    England  573      89      27  0.70     B         A
4       David      Jones  358      82      15 -1.16     F         C
8        Greg       Knox  625      95      30  1.34     A         A
5      Janice Markhammer  495      75      20 -0.63     D         B
3  Bullwinkle      Moose  412      80      18 -0.86     D         C
10       Mary    Rayburn  522      86      18 -0.18     C         B
2      Angela   Williams  600      99      22  0.92     A         A
7      Reuven    Ytzrhak  410      80      15 -1.05     F         C
> 
> #1d.
> 
> #-------------------------------------------------------------------------------------------------------
> 
> P<-quantile(roster$Science,c(0.75,0.25))
> 
> roster$ScienceGrade[roster$Science  >= P[1]]<- "A"
> roster$ScienceGrade[roster$Science  < P[1] & roster$Science >= y[2] ]<- "B"
> roster$ScienceGrade[roster$Science  < P[2]]<- "C"
> roster
    Firstname   Lastname Math Science English score grade easygrade
6      Cheryl    Cushing  512      85      28  0.35     C         B
1        John      Davis  502      95      25  0.56     B         B
9        Joel    England  573      89      27  0.70     B         A
4       David      Jones  358      82      15 -1.16     F         C
8        Greg       Knox  625      95      30  1.34     A         A
5      Janice Markhammer  495      75      20 -0.63     D         B
3  Bullwinkle      Moose  412      80      18 -0.86     D         C
10       Mary    Rayburn  522      86      18 -0.18     C         B
2      Angela   Williams  600      99      22  0.92     A         A
7      Reuven    Ytzrhak  410      80      15 -1.05     F         C
   ScienceGrade
6             B
1             A
9             B
4             B
8             A
5             C
3             C
10            B
2             A
7             C
> 
> 
> #1e.
> 
> #-------------------------------------------------------------------------------------------------------
> 
> 
> roster_2<-roster[order(-roster$Science),]
> roster_2
    Firstname   Lastname Math Science English score grade easygrade
2      Angela   Williams  600      99      22  0.92     A         A
1        John      Davis  502      95      25  0.56     B         B
8        Greg       Knox  625      95      30  1.34     A         A
9        Joel    England  573      89      27  0.70     B         A
10       Mary    Rayburn  522      86      18 -0.18     C         B
6      Cheryl    Cushing  512      85      28  0.35     C         B
4       David      Jones  358      82      15 -1.16     F         C
3  Bullwinkle      Moose  412      80      18 -0.86     D         C
7      Reuven    Ytzrhak  410      80      15 -1.05     F         C
5      Janice Markhammer  495      75      20 -0.63     D         B
   ScienceGrade
2             A
1             A
8             A
9             B
10            B
6             B
4             B
3             C
7             C
5             C
> 
> #1f.
> 
> #-------------------------------------------------------------------------------------------------------
> 
> Full<-paste(roster_2$Firstname,roster_2$Lastname)
> 
> roster_3<-cbind(Full,roster_2[,3:9])
> roster_3
                Full Math Science English score grade easygrade ScienceGrade
2    Angela Williams  600      99      22  0.92     A         A            A
1         John Davis  502      95      25  0.56     B         B            A
8          Greg Knox  625      95      30  1.34     A         A            A
9       Joel England  573      89      27  0.70     B         A            B
10      Mary Rayburn  522      86      18 -0.18     C         B            B
6     Cheryl Cushing  512      85      28  0.35     C         B            B
4        David Jones  358      82      15 -1.16     F         C            B
3   Bullwinkle Moose  412      80      18 -0.86     D         C            C
7     Reuven Ytzrhak  410      80      15 -1.05     F         C            C
5  Janice Markhammer  495      75      20 -0.63     D         B            C
> 
> #########################################################################################################
> 
> 
> #2a.i-iv
> 
> #-------------------------------------------------------------------------------------------------------
> 
> 
> pdf("Question#2part a,b and c.pdf")
> 
> set.seed(1)
> 
> t.data<-rt(1:1000,df=10)
> 
> hist(t.data,probability=T,ylab="Density",xlab="Data",main="Normal Approximation",
+ lty=1,lwd=3,ylim=c(0,0.5))
> 
> #2b.
> 
> #-------------------------------------------------------------------------------------------------------
> 
> curve(dnorm(x),xlim=c(-6,6),add=T,col="red",lty=3,lwd=3,ylab="Density",xlab="Data")
> 
> curve(dt(x,df=10),ylab="Density",xlab="Data",main="Normal Approximation",
+ lty=2,add=T,col="blue",ylim=c(0,0.5),lwd=3)
> 
> #2c.
> 
> #-------------------------------------------------------------------------------------------------------
> 
> legend(-4,0.5,col=c("red","blue"),lwd=c(3,3),lty=c(3,2),legend=c("Normal density curve","Student's T curve"),inset=0.2)
> 
> dev.off()
windows 
      2 
> 
> 
> #########################################################################################################
> 
> 
> #3a.
> 
> #-------------------------------------------------------------------------------------------------------
> 
> pdf("Question#3part a and b.pdf")
> 
> set.seed(1)
> 
> r.bin<-rbinom(10000, 100, 0.05)
> 
> hist(r.bin,probability=T,ylab="Probability",xlab="Data",main="Binomial(100,.05)",lty=1,lwd=3,ylim=c(0,0.2))
> 
> #3b.
> 
> #-------------------------------------------------------------------------------------------------------
> 
> n=100
> p=0.05
> mu=n*p
> sd=sqrt(n*p*(1-p))
> 
> xx<-seq(0,15,lengt=200)
> yy<-dnorm(xx,mu,sd)
> lines(xx,yy,col="blue",lty=2)
> dev.off()
windows 
      2 
> 
> #3c.
> 
> #-------------------------------------------------------------------------------------------------------
> 
> 
> pdf("Question#3part c.pdf")
> set.seed(1)
> 
> r.bin<-rbinom(10000, 100, 0.10)
> 
> hist(r.bin,probability=T,ylab="Probability",xlab="Data",main="Binomial(100,.10)",lty=1,lwd=3,ylim=c(0,0.2))
> 
> n=100
> p=0.10
> mu=n*p
> sd=sqrt(n*p*(1-p))
> 
> xx<-seq(0,20,lengt=200)
> yy<-dnorm(xx,mu,sd)
> lines(xx,yy,col="red",lty=2)
> 
> dev.off()
windows 
      2 
> 
> 
> #3d.
> 
> #-------------------------------------------------------------------------------------------------------
>  
> # We can see that the binormial distribution for p=0.5 and p=0.1 has a approximatly normal shape.However
> # the normal distribution is a continuous distribution and the binomial distribution is a discrete 
> # distribution.Therefore there is no way that the normal distribution being an exact replication of the
> # binomial distribution.Then I believe that the normal approximation for the binomial distribution 
> # should not use if np>=5 and n(1-p)>=5.
> 


Assignment 09

> #1a.i-iii
> 
> #---------------------------------------------------------------------------------------
> 
> 
>  boot.mean<-function(my.data,trim.perecent=0.2){
+ 
+     output_one<-sample(my.data,replace=T)
+      
+     output_two<-mean(output_one,trim=trim.perecent)
+ 
+     return(output_two)}
> 
> 
> #1b.
> 
> #---------------------------------------------------------------------------------------
> 
> SD<-read.table(file="http://jdhabiger.okstate.edu/StudentData.txt",header=T)
> SDS<-data.frame(SD)
> 
> set.seed(1)
> boot.mean(SDS$Fbtime)
[1] 39.28571
> boot.mean(SDS$Fbtime,trim.perecent=.10)
[1] 40.17241
> 
> 
> #2a.
> 
> #---------------------------------------------------------------------------------------
> 
> set.seed(1)
> 
> my.boot.sample<-c()
> 
> for(i in 1:10000){
+ my.boot.sample<-c(my.boot.sample,boot.mean(SDS$Fbtime)) 
+ }
> 
> mean(my.boot.sample)
[1] 28.31883
> 
> sd(my.boot.sample)
[1] 5.403937
> 
> #2b.
> 
> #---------------------------------------------------------------------------------------
> setwd("C:/Users/akaruna/Desktop/R-DATA")
> getwd()
[1] "C:/Users/akaruna/Desktop/R-DATA"
> pdf("Assignment.pdf")
> #par(mfrow=c(1,3))
> 
> 
> hist(my.boot.sample,main="Trimmed Mean Sample Distribution",probability=T,ylim=c(0,0.08))
> 
> 
> #2c.
> 
> #---------------------------------------------------------------------------------------
> 
> curve(dnorm(x,mean(my.boot.sample),sd(my.boot.sample)),add=T)
> 
> 
> #2d.
> 
> #---------------------------------------------------------------------------------------
> 
> quantile(my.boot.sample,c(0.025,0.975))
    2.5%    97.5% 
18.80357 39.29167 
> 
> 
> #3a.
> 
> #---------------------------------------------------------------------------------------
> 
> 
> boot.ci<-function(my.data,plot.it=T,trim.perecent=0.2){
+ if (plot.it==T){
+ hist(my.data,main="Trimmed Mean Sample Distribution for Q3",probability=T)
+ curve(dnorm(x,mean(my.data),sd(my.data)),add=T)}
+ 
+ CI<-quantile(my.data,probs=c(0.025,0.975))
+ 
+ 
+ 
+ #xbar<-mean(my.data)
+ #n<-length(my.data)
+ #df<-n-1
+ #MOE<-qt(alpha/2,df=df,lower.tail=FALSE)*sd(my.data)/sqrt(n)
+ #lower<-xbar-MOE
+ #upper<-xbar+MOE
+ #Interval<-c(lower=lower,upper=upper)
+ #return(Interval=Interval)
+ 
+ return(CI)
+ 
+ }
> 
> boot.ci(my.boot.sample,plot.it=T)
    2.5%    97.5% 
18.80357 39.29167 
> 
> 
> #3b.
> 
> #---------------------------------------------------------------------------------------
> 
> 
> set.seed(1)
> boot.ci(SDS$Introvert,trim.perecent=.10)
 2.5% 97.5% 
    1     8 
> dev.off()
null device 
          1 
> 


Assignment 10

> #1.
>  
> #---------------------------------------------------------------------------------
> 
> setwd("C:/Users/akaruna/Desktop/R-DATA")
> getwd()
[1] "C:/Users/akaruna/Desktop/R-DATA"
> pdf("Assignment_10.pdf")
> #par(mfrow=c(2,2))
> 
> AL<-read.table(file="http://jdhabiger.okstate.edu/StudentData.txt",header=T)
> data_one<-table(AL$Snapchat,AL$Gender)
> 
> barplot(data_one,
+         beside = TRUE,col=2:3,
+         legend=rownames(data_one), 
+         args.legend=list(title="snapchat"), 
+         main="snapchat vs. gender counts",
+         xlab="Gender")
> 
> 
> #2.
>  
> #---------------------------------------------------------------------------------
> 
> median_HSC<-aggregate(HSClass~Pinterest,data=AL,FUN=median)
> 
> barplot(median_HSC$HSClass,
+         col=2:3,
+         names.arg=c("No Pinterest","Pinterest"),
+         main="Median HSClass vs. Pinterest",
+         ylab="Median HSClass")
>          
> #3.
>  
> #---------------------------------------------------------------------------------
> 
> hist(AL$HSClass,
+      freq=F, 
+      probability=T, 
+      ylab="Density",
+      xlab="HSClass Data",
+      col=2,
+      main="Histogram of HSClass")
> 
> lines(density(AL$HSClass),lwd=3,lty=2,col="green") 
> 
> curve(dnorm(x, mean=mean(AL$HSClass), 
+       sd=sd(AL$HSClass)), 
+       col="blue", 
+       lwd=4, 
+       add=TRUE, 
+       lty=1) 
> 
> legend("topright",
+         legend=c("kernel","normal"),
+         lty=c(2,1),
+         lwd=c(3,4),
+         col=c("green","blue"),
+         inset=0.05)
> 
> 
> #4.
>  
> #---------------------------------------------------------------------------------
> 
> 
> pct<-round(USPersonalExpenditure[,5]/sum(USPersonalExpenditure[,5])*100)
> 
> name_and_pct<-paste(rownames(USPersonalExpenditure)," ",pct,"%",sep=" ")
> 
> pie(USPersonalExpenditure[,5],
+     labels=name_and_pct,
+     col=rainbow(length(rownames(USPersonalExpenditure))),
+     main="US Personal Expenditure Data",
+     radius=0.6)
> 
> dev.off()
pdf 
  2 
> 
> 



Assignment 11

> #1.
>   
> #---------------------------------------------------------------------------------
> 
> 
> setwd("C:/Users/akaruna/Desktop/R-DATA")
> 
> getwd()
[1] "C:/Users/akaruna/Desktop/R-DATA"
> 
> pdf("Assignment_11.pdf")
> 
> par(mfrow=c(2,1))
> 
> set.seed(5)
> 
> x<-rlnorm(50,meanlog=0,sdlog=2)
> 
> summary<-boxplot.stats(x)
> 
> outlier_cutoff<-summary$stats[4]+5*(summary$stats[4]-summary$stats[2])
> 
> boxplot(x,main="Boxplot of lognormal data",col="blue",yaxt="n",pch="x",range=5)
> 
> axis(2,at=summary$stats[3],labels="M=0.75")
> 
> abline(h=outlier_cutoff,col=2,lty=2)
> 
> axis(4,at=x,tick=T,labels=F)
> 
> legend("topright",legend="outlier",inset = .05,pch="x")
> 
> 
> #2.
>   
> #---------------------------------------------------------------------------------
> 
>  
> AL<-read.table(file="http://jdhabiger.okstate.edu/StudentData.txt",header=T)
> 
> my_col = c(rep("pink",2),rep("blue",2))
> 
> boxplot(AL$Fbtime ~AL$Snapchat*AL$Gender,
+         col=my_col,
+         main="FBtime vs Snapchat byGender",
+         ylab="FBtime",
+         names=c("No Snapchat","Snapchat","No Snapchat","Snapchat"),
+         xlab="")
> 
> legend("topleft",legend=c("Female","Male"),inset = .05,col=c("pink","blue"),
+         fill=c("pink","blue"))
> 
> dev.off()
pdf 
  3 
> 
> #3.
>   
> #---------------------------------------------------------------------------------
> 
> aggregate(AL[,c(3:6,9)],by=list(Snapchat=AL$Snapchat,Gender=AL$Gender),
+           FUN=median)
  Snapchat Gender HSClass TxtSent TxtRec Fbtime Introvert
1        N      F     105     7.5    7.5   12.5       4.5
2        Y      F     220    75.0   75.0   30.0       5.0
3        N      M     326    10.0   15.0   30.0       6.0
4        Y      M     142    30.0   30.0   20.0       5.0
> 
> aggregate(AL[,c(3:6,9)],by=list(Snapchat=AL$Snapchat,Gender=AL$Gender),
+          FUN=mean,trim=0.05)
  Snapchat Gender  HSClass  TxtSent   TxtRec   Fbtime Introvert
1        N      F 186.6250 11.62500 12.25000 25.00000  4.875000
2        Y      F 442.0667 71.20000 72.20000 45.00000  4.733333
3        N      M 287.3333 15.00000 18.33333 31.66667  5.666667
4        Y      M 251.4444 52.22222 63.22222 25.55556  4.722222
> 
> 


Assignment 12

> #1a.
>    
> #-------------------------------------------------------------------------------
> 
> AL<-read.table(file="http://jdhabiger.okstate.edu/StudentData.txt",header=T)
> 
> AB<-table(AL$Gender ,AL$Pinterest)
> 
> #1b.
>    
> #-------------------------------------------------------------------------------
> 
> prop.table(AB)
   
             N          Y
  F 0.28571429 0.37142857
  M 0.28571429 0.05714286
> 
> 
> #1c.
>    
> #-------------------------------------------------------------------------------
> 
> resid(chisq.test(AB))
   
             N          Y
  F -0.8669214  1.0010347
  M  1.2001984 -1.3858697
> 
> #yes. There are more female Pinterestn users than expected.Because 1.0010347 > 0.
> 
> 
> #1d-e.
>    
> #-------------------------------------------------------------------------------
> 
> fisher.test(AB)

        Fisher's Exact Test for Count Data

data:  AB
p-value = 0.03397
alternative hypothesis: true odds ratio is not equal to 1
95 percent confidence interval:
 0.01419334 1.01695124
sample estimates:
odds ratio 
 0.1623948 

> 
> barplot(t(AB),col=c("red","blue"),beside=T,legend=rownames(t(AB)),
+         main="Pinterest Depends on Gender (p =0.03397 )" ,
+         args.legend=list(title="Pinterest"),xlab="Gender")
> 
> #2a.
>    
> #-------------------------------------------------------------------------------
> 
> str(Titanic)
 'table' num [1:4, 1:2, 1:2, 1:2] 0 0 35 0 0 0 17 0 118 154 ...
 - attr(*, "dimnames")=List of 4
  ..$ Class   : chr [1:4] "1st" "2nd" "3rd" "Crew"
  ..$ Sex     : chr [1:2] "Male" "Female"
  ..$ Age     : chr [1:2] "Child" "Adult"
  ..$ Survived: chr [1:2] "No" "Yes"
> 
> Titanic
, , Age = Child, Survived = No

      Sex
Class  Male Female
  1st     0      0
  2nd     0      0
  3rd    35     17
  Crew    0      0

, , Age = Adult, Survived = No

      Sex
Class  Male Female
  1st   118      4
  2nd   154     13
  3rd   387     89
  Crew  670      3

, , Age = Child, Survived = Yes

      Sex
Class  Male Female
  1st     5      1
  2nd    11     13
  3rd    13     14
  Crew    0      0

, , Age = Adult, Survived = Yes

      Sex
Class  Male Female
  1st    57    140
  2nd    14     80
  3rd    75     76
  Crew  192     20

> 
> one<-margin.table(Titanic,c(1,4))
> 
> prop.table(one)
      Survived
Class          No        Yes
  1st  0.05542935 0.09223080
  2nd  0.07587460 0.05361199
  3rd  0.23989096 0.08087233
  Crew 0.30577010 0.09631985
> 
> #2b.
>    
> #-------------------------------------------------------------------------------
> 
> 
> chisq.test(one)

        Pearson's Chi-squared test

data:  one
X-squared = 190.4, df = 3, p-value < 2.2e-16

> 
> # p-value is 2.2e-16 and it is significantly low.Then we reject the null hypothesis.
> # Therefore survival rate depend on class.
> 
> 
> #2c.
>    
> #-------------------------------------------------------------------------------
> 
> two<-margin.table(Titanic,c(2,4))
> 
> prop.table(two,2)
        Survived
Sex              No        Yes
  Male   0.91543624 0.51617440
  Female 0.08456376 0.48382560
> 
> # Male has the highest survival rate which is 0.51617440.
> 
> 


Assignment 13

> #1a.
>   
> #---------------------------------------------------------------------------------
> 
> setwd("C:/Users/akaruna/Desktop/R-DATA")
> getwd()
[1] "C:/Users/akaruna/Desktop/R-DATA"
> 
> pdf("Assignment_13.pdf")
> 
> ST_Data<-read.table(file="http://jdhabiger.okstate.edu/StudentData.txt",header=T)
> 
> t.test(ST_Data$Fbtime)

        One Sample t-test

data:  ST_Data$Fbtime
t = 6.5348, df = 34, p-value = 1.755e-07
alternative hypothesis: true mean is not equal to 0
95 percent confidence interval:
 23.62330 44.94813
sample estimates:
mean of x 
 34.28571 

> 
> #We are 95% confident that mean Facebook time is in between 23.62330 and 44.94813.
> 
> 
> 
> #1b.
>   
> #---------------------------------------------------------------------------------
> 
> boxplot(ST_Data$Fbtime~ST_Data$Snapchat,
+         xlab="Snapchat",
+         ylab="Fbtime",
+         main="FBtime vs. Snapchat",
+         col=c(2,3))
> 
> # We can see that the variance across samples for facebook time among snapchat users
> # is higher than facebook time among non-snapchat users.
> 
> #1c.
>   
> #---------------------------------------------------------------------------------
> 
> FB_with_snap<-ST_Data[ST_Data$Snapchat=='Y',]$Fbtime
> 
> FB_without_snap<-ST_Data[ST_Data$Snapchat=='N',]$Fbtime
> 
> t.test(FB_with_snap,FB_without_snap, var.equal=F, conf.level=.95)

        Welch Two Sample t-test

data:  FB_with_snap and FB_without_snap
t = 1.0288, df = 23.024, p-value = 0.3143
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -11.00629  32.78659
sample estimates:
mean of x mean of y 
 37.70833  26.81818 

> 
> # p-value = 0.3143
> 
> #1d.
>   
> #---------------------------------------------------------------------------------
> 
> FB_with_snap<-ST_Data[ST_Data$Snapchat=='Y',]$Fbtime
> 
> FB_without_snap<-ST_Data[ST_Data$Snapchat=='N',]$Fbtime
> 
> t.test(FB_with_snap,FB_without_snap, var.equal=F, conf.level=.9)

        Welch Two Sample t-test

data:  FB_with_snap and FB_without_snap
t = 1.0288, df = 23.024, p-value = 0.3143
alternative hypothesis: true difference in means is not equal to 0
90 percent confidence interval:
 -7.251187 29.031490
sample estimates:
mean of x mean of y 
 37.70833  26.81818 

> 
> # p-value is 0.3143 and it is larger than 0.1. Therefore we fail to reject null hypothesis. 
> # Then we can say there is no significant difference between mean facebook time among snapchat
> # users and no-snapchat users. 
> 
> #2a.
>   
> #---------------------------------------------------------------------------------
> 
> attach(USArrests)
The following objects are masked from USArrests (pos = 3):

    Assault, Murder, Rape, UrbanPop

> 
> plot(Assault ,Murder,
+      xlab="Assault", 
+      ylab="Murder",
+      main="Murder vs. Assault",
+      col="Blue")
> 
> model_1<-lm(Murder~Assault)
> 
> abline(model_1,col="red")
> 
> #2b.
>   
> #---------------------------------------------------------------------------------
> 
> chisq.test(Murder, Assault)

        Pearson's Chi-squared test

data:  Murder and Assault
X-squared = 1891.7, df = 1848, p-value = 0.2346

Warning message:
In chisq.test(Murder, Assault) : Chi-squared approximation may be incorrect
> 
> # Here we have assumed that data are normally distributed.
> # We consider 95% confidence interval.
> # p-value = 0.2346 is larger that alpha=0.05 then we fail to 
> # reject Null hypothesis. There fore Murder and Assault are depended.
> 
> 
> #2c.
>   
> #---------------------------------------------------------------------------------
> 
> predict_interval_1 <- predict(model_1, new=data.frame(Assault=151), interval="prediction") 
> predict_interval_1
       fit      lwr      upr
1 6.959886 1.617596 12.30218
> 
> 
> #2d.
>   
> #---------------------------------------------------------------------------------
> 
> Assault.values<-seq(min(Assault),max(Assault), 100)
> 
> 
> predict_interval_2 <- predict(model_1, newdata=data.frame(Assault=Assault.values), 
+                       interval="prediction")
> 
> lines(Assault.values, predict_interval_2[,2],col="blue", lty=2)
> 
> 
> lines(Assault.values, predict_interval_2[,3],col="blue", lty=2)
> 
> dev.off()
windows 
      2 
> 
